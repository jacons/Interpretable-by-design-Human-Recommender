{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Download & Install the packages"
   ],
   "metadata": {
    "id": "gHt4mLVmPZRj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "!git clone https://github.com/jacons/ilmart\n",
    "!git clone --recurse-submodules https://github.com/veneres/LightGBM.git\n",
    "!pip install rankeval\n",
    "%cd LightGBM/python-package\n",
    "!python setup.py install\n",
    "%cd ../../ilmart\n",
    "!pip install -e .\n",
    "%cd ../ilmart"
   ],
   "metadata": {
    "id": "gGOPgqJtgFBK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import ndcg_score\n",
    "from src.ilmart import Ilmart, IlmartDistill, utils\n",
    "import lightgbm as lgbm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "id": "F2v-vZbs6o5G"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Grid search implementation"
   ],
   "metadata": {
    "id": "OSRTZqWDPk6z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class ILMARTGridsearch:\n",
    "  def __init__(self, name: str, path: str = None, nDCG_at: int = 15):\n",
    "\n",
    "    self.train = pd.read_csv(f\"{path}{name}_dataset_tr.csv\")\n",
    "    self.valid = pd.read_csv(f\"{path}{name}_dataset_vl.csv\")\n",
    "    self.test = pd.read_csv(f\"{path}{name}_dataset_ts.csv\")\n",
    "\n",
    "    # sorting after the splitting\n",
    "    self.train.sort_values([\"qId\", \"kId\"], inplace=True)\n",
    "    self.valid.sort_values([\"qId\", \"kId\"], inplace=True)\n",
    "    self.test.sort_values([\"qId\", \"kId\"], inplace=True)\n",
    "\n",
    "    # Preparing the datasets\n",
    "    self.qIds_train = self.train.groupby(\"qId\")[\"qId\"].count().to_numpy()\n",
    "    self.X_train, self.y_train = self.train.iloc[:, 5:], self.train[[\"qId\", \"kId\", \"relevance\"]]\n",
    "    self.qIds_valid = self.valid.groupby(\"qId\")[\"qId\"].count().to_numpy()\n",
    "    self.X_valid, self.y_valid = self.valid.iloc[:, 5:], self.valid[[\"qId\", \"kId\", \"relevance\"]]\n",
    "    self.qIds_test = self.test.groupby(\"qId\")[\"qId\"].count().to_numpy()\n",
    "    self.X_test, self.y_test = self.test.iloc[:, 5:], self.test[[\"qId\", \"kId\", \"relevance\"]]\n",
    "\n",
    "    self.default_par = dict(\n",
    "      objective=\"lambdarank\",\n",
    "      boosting_type=\"gbdt\",\n",
    "      metric=\"ndcg\",\n",
    "      force_row_wise=True,\n",
    "      n_jobs=-1,\n",
    "      verbose = -1\n",
    "    )\n",
    "    self.ranker_par = dict(  # default ranker parameters (used in fitting) pt.2\n",
    "      X_train=self.X_train.to_numpy(),\n",
    "      y_train=self.y_train[\"relevance\"].to_numpy(),\n",
    "      group_train=self.qIds_train,\n",
    "      X_valid = self.X_valid.to_numpy(),\n",
    "      y_valid = self.y_valid[\"relevance\"].to_numpy(),\n",
    "      group_valid=self.qIds_valid,\n",
    "    )\n",
    "\n",
    "    self.nDCG_at = nDCG_at\n",
    "    return\n",
    "\n",
    "  def eval_model(self, model, df: pd.DataFrame = None,\n",
    "                 qIds: np.ndarray = None, nDCG_at: list = None) -> dict:\n",
    "      \"\"\"\n",
    "      Custom evaluation function: the function groups by the \"job-offers\" and foreach set, it predicts\n",
    "      the \"lambdas\" that it uses to sort (by relevance).\n",
    "      After obtained nDCGs apply the average.\n",
    "      \"\"\"\n",
    "      df = self.valid if df is None else df\n",
    "      n_qIds = len(self.qIds_valid) if qIds is None else len(qIds)\n",
    "      nDCG_at = [self.nDCG_at] if nDCG_at is None else nDCG_at\n",
    "      avg_nDCG = np.zeros((len(nDCG_at)))\n",
    "\n",
    "      for _, v in df.groupby(\"qId\"):\n",
    "\n",
    "          features, target = v.iloc[:, 5:].to_numpy(), np.asarray([v[\"w_score\"].to_numpy()])\n",
    "          lambdas = np.asarray([model.get_model().predict(features)])  # predict lambdas\n",
    "\n",
    "          # Perform the nDCG for a specific job-offer and then sum it into cumulative nDCG\n",
    "          for i, nDCG in enumerate(nDCG_at):\n",
    "              avg_nDCG[i] += ndcg_score(target, lambdas, k=nDCG)\n",
    "\n",
    "      # dived by the number of jobs-offer to obtain the average.\n",
    "      avg_nDCG /= n_qIds\n",
    "      results = {\"nDCG@\"+str(nDCG): round(avg_nDCG[i], 4) for i, nDCG in enumerate(nDCG_at)}\n",
    "      return results\n",
    "\n",
    "  def fit(self, **conf):\n",
    "\n",
    "      model = Ilmart(verbose=False)\n",
    "      all_params = { **self.default_par, **conf}\n",
    "      model.fit(all_params,**self.ranker_par)\n",
    "      return model\n",
    "\n",
    "  def grid_search(self, hyperparameters: dict = None) -> Tuple:\n",
    "      # keep the current: (best_model, best_params, best nDCG)\n",
    "      best_model_: Tuple = (None, None, -sys.maxsize)\n",
    "\n",
    "      # explore all possible combinations of hyperparameters\n",
    "      progress_bar = tqdm(ParameterGrid(hyperparameters))\n",
    "      for conf in progress_bar:\n",
    "          model = self.fit(**conf)\n",
    "          avg_nDCG = self.eval_model(model)[\"nDCG@\"+str(self.nDCG_at)]\n",
    "\n",
    "          # if the model is better respect to the previous one, it updates the tuple\n",
    "          if avg_nDCG > best_model_[2]:\n",
    "              best_model_ = (model, conf, avg_nDCG)\n",
    "          progress_bar.set_postfix(nDCG_15=best_model_[2])\n",
    "      return best_model_"
   ],
   "metadata": {
    "id": "-pw9M8bo7oWS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ilMart_parameter = dict(\n",
    "    num_leaves=[2, 5, 10, 20, 30, 40],\n",
    "    max_depth=[-1],\n",
    "    learning_rate=[0.02, 0.05, 0.08, 0.1, 0.15, 0.2],\n",
    "    reg_lambda=[0.00005, 0.0001, 0.0002, 0.0003]\n",
    ")\n",
    "gridsearch_parameters = dict(\n",
    "    path=\"https://raw.githubusercontent.com/jacons/Interpretable-by-design-Human-Recommender/master/outputs/scores/\",\n",
    "    name=\"0\",\n",
    "    nDCG_at=15\n",
    ")"
   ],
   "metadata": {
    "id": "7185VSOe5JkI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "gs = ILMARTGridsearch(**gridsearch_parameters)\n",
    "best_ = gs.grid_search(ilMart_parameter)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uV6fI2T9cGpu",
    "outputId": "f209b3bd-c1ff-4854-c50b-bd51ec7b88f3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "best_"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xv_HHH0mJxBb",
    "outputId": "6b65d0e0-eb1d-4f24-e128-59e8c03336a2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# nDCG\n",
    "nDCG_train = gs.eval_model(model=best_[0], df=gs.train, qIds=gs.qIds_train, nDCG_at=[1,10,15])\n",
    "nDCG_valid = gs.eval_model(model=best_[0], df=gs.valid, qIds=gs.qIds_valid, nDCG_at=[1,10,15])\n",
    "nDCG_test = gs.eval_model(model=best_[0], df=gs.test, qIds=gs.qIds_test, nDCG_at=[1,10,15])\n",
    "\n",
    "display(pd.DataFrame([nDCG_train,nDCG_valid,nDCG_test],index=[\"Training\",\"Validation\",\"Test\"]))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "KgKy6Se7Jiqq",
    "outputId": "15df4ed2-4262-48ee-f5ce-d31f6e8f8ba8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "best_[0].get_model().save_model(\"file_name.lgbm\")\n",
    "best_model = lgbm.Booster(model_file=\"file_name.lgbm\")\n",
    "distilled_best_model = IlmartDistill(best_model)"
   ],
   "metadata": {
    "id": "WGEZosQD-sua"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature importance"
   ],
   "metadata": {
    "id": "mjnZpYU0NKOg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "id2feature = {i:v for i,v in enumerate(list(gs.X_train.columns))}"
   ],
   "metadata": {
    "id": "rulQGas_RZfZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "list_features = list(gs.X_train.columns)\n",
    "features_importance = best_model.feature_importance()\n",
    "order_idx = np.argsort(features_importance)\n",
    "features_importance = features_importance[order_idx]\n",
    "labels_name = [list_features[i] for i in order_idx]"
   ],
   "metadata": {
    "id": "sqRapl40NjG1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.barh(range(len(features_importance)), features_importance, color=\"#a74e25\")\n",
    "plt.grid(color='grey', linestyle='-.', linewidth=0.5, alpha=0.5)\n",
    "plt.yticks(range(len(features_importance)), labels_name)\n",
    "plt.title('Features importance')\n",
    "plt.xlabel('Features importance')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "JoxQLmFKMLKd",
    "outputId": "f8246792-75dc-408a-9073-6a95257d54ab"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Explain the model"
   ],
   "metadata": {
    "id": "YcMYZ_UaP5A7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def pairwise_function(cuts, contribution, value: float) -> float:\n",
    "  if value < cuts[0]:\n",
    "      return contribution[0]\n",
    "  for i in range(len(cuts)-1):\n",
    "      if cuts[i] <= value <= cuts[i+1]:\n",
    "          return contribution[i+1]\n",
    "  if value > cuts[-1]:\n",
    "      return contribution[-1]\n",
    "\n",
    "def explanation(model, index_feature: int, eps: float = 0.01) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "  min_, max_ = gs.X_train.iloc[:,index_feature].min(), gs.X_train.iloc[:,index_feature].max()\n",
    "  cuts = model.splitting_values[index_feature][1:-1]\n",
    "  contrib = model.hist[(index_feature,)]\n",
    "  x = np.arange(min_, max_, eps)\n",
    "  y = [pairwise_function(cuts, contrib, v_) for v_ in x]\n",
    "  return x, y"
   ],
   "metadata": {
    "id": "gA9Doap3P4kM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "f, axs = plt.subplots(ncols=3,nrows=2,figsize=(20,8))\n",
    "\n",
    "for i, feature in enumerate(order_idx[::-1][:6]):\n",
    "\n",
    "    x,y = explanation(distilled_best_model, feature)\n",
    "    axs[int(i/3)][i%3].set_xlabel(\"Value\")\n",
    "    axs[int(i/3)][i%3].set_ylabel(\"Contribute\")\n",
    "    axs[int(i/3)][i%3].grid()\n",
    "    axs[int(i/3)][i%3].plot(x,y, label=id2feature[feature], color=\"#a74e25\")\n",
    "    axs[int(i/3)][i%3].legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "id": "Qiv0ap3RTkw-",
    "outputId": "20bf6b11-26f7-4e46-dbfa-ec2de0118497"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gs.test[gs.test[\"qId\"]==15][[\"kId\",\"relevance\"]].sort_values(\"relevance\",ascending=False).head(15)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "features = gs.test[gs.test[\"qId\"]==15]\n",
    "y_pred = best_model.predict(np.asarray(features.iloc[:,5:].values))\n",
    "y_pred = pd.DataFrame(y_pred, index=features.index, columns=[\"lambdas\"])\n",
    "dt_final = pd.merge(features, y_pred, left_index=True, right_index=True)\n",
    "dt_final.sort_values(\"lambdas\",ascending=False)[[\"kId\",\"w_score\"]].head(15)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "Qzn436fxYqu-",
    "outputId": "a7217334-4321-4c35-d9dd-6c863faff52a"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
