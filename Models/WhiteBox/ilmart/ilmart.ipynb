{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# # Download & Install the packages"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b243fe92b68f6168"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%capture\n",
    "!git clone https://github.com/jacons/ilmart\n",
    "!git clone --recurse-submodules https://github.com/veneres/LightGBM.git\n",
    "!pip install rankeval\n",
    "%cd LightGBM/python-package\n",
    "!python setup.py install\n",
    "%cd ../../ilmart\n",
    "!pip install -e .\n",
    "%cd ../ilmart"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "461914eb0a04882d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import ndcg_score\n",
    "from src.ilmart import Ilmart, IlmartDistill, utils\n",
    "import lightgbm as lgbm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \"is_categorical_dtype\")\n",
    "warnings.filterwarnings(\"ignore\", \"use_inf_as_na\")\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b541c2ec77785687"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# # Grid search implementation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "836f8ebcccafd758"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ILMARTGridsearch:\n",
    "  def __init__(self, name: str, path: str = None, nDCG_at: int = 15):\n",
    "\n",
    "    self.train = pd.read_csv(f\"{path}{name}_dataset_tr.csv\")\n",
    "    self.valid = pd.read_csv(f\"{path}{name}_dataset_vl.csv\")\n",
    "    self.test = pd.read_csv(f\"{path}{name}_dataset_ts.csv\")\n",
    "\n",
    "    # sorting after the splitting\n",
    "    self.train.sort_values([\"qId\", \"kId\"], inplace=True)\n",
    "    self.valid.sort_values([\"qId\", \"kId\"], inplace=True)\n",
    "    self.test.sort_values([\"qId\", \"kId\"], inplace=True)\n",
    "\n",
    "    # Preparing the datasets\n",
    "    self.qIds_train = self.train.groupby(\"qId\")[\"qId\"].count().to_numpy()\n",
    "    self.X_train, self.y_train = self.train.iloc[:, 5:], self.train[[\"qId\", \"kId\", \"binned_relevance\"]]\n",
    "    self.qIds_valid = self.valid.groupby(\"qId\")[\"qId\"].count().to_numpy()\n",
    "    self.X_valid, self.y_valid = self.valid.iloc[:, 5:], self.valid[[\"qId\", \"kId\", \"binned_relevance\"]]\n",
    "    self.qIds_test = self.test.groupby(\"qId\")[\"qId\"].count().to_numpy()\n",
    "    self.X_test, self.y_test = self.test.iloc[:, 5:], self.test[[\"qId\", \"kId\", \"binned_relevance\"]]\n",
    "\n",
    "    self.default_par = dict(\n",
    "      objective=\"lambdarank\",\n",
    "      boosting_type=\"gbdt\",\n",
    "      metric=\"ndcg\",\n",
    "      force_row_wise=True,\n",
    "      n_jobs=-1,\n",
    "      verbose = -1\n",
    "    )\n",
    "    self.ranker_par = dict(  # default ranker parameters (used in fitting) pt.2\n",
    "      X_train=self.X_train.to_numpy(),\n",
    "      y_train=self.y_train[\"binned_relevance\"].to_numpy(),\n",
    "      group_train=self.qIds_train,\n",
    "      X_valid = self.X_valid.to_numpy(),\n",
    "      y_valid = self.y_valid[\"binned_relevance\"].to_numpy(),\n",
    "      group_valid=self.qIds_valid,\n",
    "    )\n",
    "\n",
    "    self.nDCG_at = nDCG_at\n",
    "    return\n",
    "\n",
    "  def eval_model(self, model, df: pd.DataFrame = None,\n",
    "                 qIds: np.ndarray = None, nDCG_at: list = None) -> dict:\n",
    "      \"\"\"\n",
    "      Custom evaluation function: the function groups by the \"job-offers\" and foreach set, it predicts\n",
    "      the \"lambdas\" that it uses to sort (by binned_relevance).\n",
    "      After obtained nDCGs apply the average.\n",
    "      \"\"\"\n",
    "      df = self.valid if df is None else df\n",
    "      n_qIds = len(self.qIds_valid) if qIds is None else len(qIds)\n",
    "      nDCG_at = [self.nDCG_at] if nDCG_at is None else nDCG_at\n",
    "      avg_nDCG = np.zeros((len(nDCG_at)))\n",
    "\n",
    "      for _, v in df.groupby(\"qId\"):\n",
    "\n",
    "          features, target = v.iloc[:, 5:].to_numpy(), np.asarray([v[\"relevance\"].to_numpy()])\n",
    "          lambdas = np.asarray([model.get_model().predict(features)])  # predict lambdas\n",
    "\n",
    "          # Perform the nDCG for a specific job-offer and then sum it into cumulative nDCG\n",
    "          for i, nDCG in enumerate(nDCG_at):\n",
    "              avg_nDCG[i] += ndcg_score(target, lambdas, k=nDCG)\n",
    "\n",
    "      # dived by the number of jobs-offer to obtain the average.\n",
    "      avg_nDCG /= n_qIds\n",
    "      results = {\"nDCG@\"+str(nDCG): round(avg_nDCG[i], 4) for i, nDCG in enumerate(nDCG_at)}\n",
    "      return results\n",
    "\n",
    "  def fit(self, **conf):\n",
    "\n",
    "      model = Ilmart(verbose=False)\n",
    "      all_params = { **self.default_par, **conf}\n",
    "      model.fit(all_params,**self.ranker_par)\n",
    "      return model\n",
    "\n",
    "  def grid_search(self, hyperparameters: dict = None) -> Tuple:\n",
    "      # keep the current: (best_model, best_params, best nDCG)\n",
    "      best_model_: Tuple = (None, None, -sys.maxsize)\n",
    "\n",
    "      # explore all possible combinations of hyperparameters\n",
    "      progress_bar = tqdm(ParameterGrid(hyperparameters))\n",
    "      for conf in progress_bar:\n",
    "          model = self.fit(**conf)\n",
    "          avg_nDCG = self.eval_model(model)[\"nDCG@\"+str(self.nDCG_at)]\n",
    "\n",
    "          # if the model is better respect to the previous one, it updates the tuple\n",
    "          if avg_nDCG > best_model_[2]:\n",
    "              best_model_ = (model, conf, avg_nDCG)\n",
    "          progress_bar.set_postfix(nDCG_15=best_model_[2])\n",
    "      return best_model_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "595113a215745371"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ilMart_parameter = dict(\n",
    "    num_leaves=[2, 3 , 4, 5, 6],\n",
    "    max_depth=[2, 3],\n",
    "    learning_rate=[0.02, 0.05, 0.08, 0.1, 0.15, 0.2],\n",
    "    reg_lambda=[0.00005, 0.0001, 0.0002, 0.0003]\n",
    ")\n",
    "gridsearch_parameters = dict(\n",
    "    path=\"https://raw.githubusercontent.com/jacons/Interpretable-by-design-Human-Recommender/master/outputs/scores/\",\n",
    "    name=\"0\",\n",
    "    nDCG_at=15\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8dec53ce82912871"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gs = ILMARTGridsearch(**gridsearch_parameters)\n",
    "best_ = gs.grid_search(ilMart_parameter)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e0791207d653e82"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c60eee341f8c1c2a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# nDCG\n",
    "nDCG_train = gs.eval_model(model=best_[0], df=gs.train, qIds=gs.qIds_train, nDCG_at=[1,10,15])\n",
    "nDCG_valid = gs.eval_model(model=best_[0], df=gs.valid, qIds=gs.qIds_valid, nDCG_at=[1,10,15])\n",
    "nDCG_test = gs.eval_model(model=best_[0], df=gs.test, qIds=gs.qIds_test, nDCG_at=[1,10,15])\n",
    "\n",
    "display(pd.DataFrame([nDCG_train,nDCG_valid,nDCG_test],index=[\"Training\",\"Validation\",\"Test\"]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a8202544122dab"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_[0].get_model().save_model(\"file_name.lgbm\")\n",
    "best_model = lgbm.Booster(model_file=\"file_name.lgbm\")\n",
    "distilled_best_model = IlmartDistill(best_model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43e9464a9b59d4fc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# # Feature importance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "daf08e38f6e2b1d5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "uri2feature = {i:v for i,v in enumerate(list(gs.X_train.columns))}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e357ec76d9b9bd5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "list_features = list(gs.X_train.columns)\n",
    "features_importance = best_model.feature_importance()\n",
    "order_idx = np.argsort(features_importance)\n",
    "features_importance = features_importance[order_idx]\n",
    "labels_name = [list_features[i] for i in order_idx]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ae6086f02eaad3c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.barh(range(len(features_importance)), features_importance, color=\"#a74e25\")\n",
    "plt.grid(color='grey', linestyle='-.', linewidth=0.5, alpha=0.5)\n",
    "plt.yticks(range(len(features_importance)), labels_name)\n",
    "plt.title('Features importance')\n",
    "plt.xlabel('Features importance')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ec9cfd15dfb616c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# # Explain the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38c185379c955c83"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def pairwise_function(cuts, contribution, value: float) -> float:\n",
    "  if value < cuts[0]:\n",
    "      return contribution[0]\n",
    "  for i in range(len(cuts)-1):\n",
    "      if cuts[i] <= value <= cuts[i+1]:\n",
    "          return contribution[i+1]\n",
    "  if value > cuts[-1]:\n",
    "      return contribution[-1]\n",
    "\n",
    "def explanation(model, index_feature: int, eps: float = 0.01) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "  min_, max_ = gs.X_train.iloc[:,index_feature].min(), gs.X_train.iloc[:,index_feature].max()\n",
    "  cuts = model.splitting_values[index_feature][1:-1]\n",
    "  contrib = model.hist[(index_feature,)]\n",
    "  x = np.arange(min_, max_, eps)\n",
    "  y = [pairwise_function(cuts, contrib, v_) for v_ in x]\n",
    "  return x, y"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99c5aa772903e8f9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(ncols=3,nrows=2,figsize=(20,8))\n",
    "\n",
    "for i, feature in enumerate(order_idx[::-1][:6]):\n",
    "\n",
    "    x,y = explanation(distilled_best_model, feature)\n",
    "    axs[int(i/3)][i%3].set_xlabel(\"Value\")\n",
    "    axs[int(i/3)][i%3].set_ylabel(\"Contribute\")\n",
    "    axs[int(i/3)][i%3].grid()\n",
    "    axs[int(i/3)][i%3].plot(x,y, label=uri2feature[feature], color=\"#a74e25\")\n",
    "    axs[int(i/3)][i%3].legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5df98219c5e3f650"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gs.test[gs.test[\"qId\"]==15][[\"kId\",\"binned_relevance\"]].sort_values(\"binned_relevance\",ascending=False).head(15)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33eddbddad408534"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "features = gs.test[gs.test[\"qId\"]==15]\n",
    "y_pred = best_model.predict(np.asarray(features.iloc[:,5:].values))\n",
    "y_pred = pd.DataFrame(y_pred, index=features.index, columns=[\"lambdas\"])\n",
    "dt_final = pd.merge(features, y_pred, left_index=True, right_index=True)\n",
    "dt_final.sort_values(\"lambdas\",ascending=False)[[\"kId\",\"relevance\"]].head(15)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d3091a6771525f6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
